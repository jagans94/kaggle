{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4c08f48-fe23-4ddb-ac46-d97f05397514",
    "_uuid": "f2156d1dd26a1243e18512002e10872c5bd7271e"
   },
   "source": [
    "# Dog Breed Classification\n",
    "\n",
    "**Overview:**\n",
    "- What I've learned:\n",
    "- Loading, Testing and Cleaning Data\n",
    "- Preparing Data\n",
    "- Visualizing Data\n",
    "- Splitting Train Data: ~ Optional\n",
    "- Building Model\n",
    "- Training Model\n",
    "- Evaluating Model\n",
    "- Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What I've learned:\n",
    "- Concepts:\n",
    "- Functions:\n",
    "    - [pandas.DataFrame.describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)\n",
    "    - [value_counts()](https://stackoverflow.com/questions/22391433/count-the-frequency-that-a-value-occurs-in-a-dataframe-column)\n",
    "    - [pandas.DataFrame.head](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f67b9393-8ea1-4e23-b856-2ce149cfe421",
    "_execution_state": "idle",
    "_uuid": "72334cb006d02a4bcfc2a2fe622524eba824c6f8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**\n",
    "\n",
    "1. Download and move the dataset to `../dataset` folder.\n",
    "2. Unpack the zipped files (optionally delete the zip files after unpacking)\n",
    "3. Visualize/Inspect the dataset.\n",
    "4. Follow chapter 5 of 'Deep Learning with Python' by Franchois Chollet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagan\\Anaconda3\\envs\\deep-learning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from helper_scripts import my_func_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\projects\\kaggle\\competitions\n",
      "labels.csv.zip\n",
      "sample_submission.csv.zip\n",
      "test.zip\n",
      "train.zip\n"
     ]
    }
   ],
   "source": [
    "my_func_utils.unzip_dataset('..\\datasets\\dog_breed_identification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading, Testing  and Cleaning Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5e51d00e-62fd-4141-bf73-50ac4f2da7d0",
    "_execution_state": "idle",
    "_uuid": "84bbd5ab8d7895bd430d5ecfe2f7ddf77baa7b74"
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "data_train = pd.read_csv(\"../datasets/digit-recognizer/train.csv\")\n",
    "data_test = pd.read_csv(\"../datasets/digit-recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TLDR**: The data is clean ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool way to quickly check if you've null values. If `unique` > 1 then you've null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the ferquency of occurrence of each sub class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "86570a36-5c20-460a-9dfd-2070548532a7",
    "_execution_state": "idle",
    "_uuid": "1213b979d5ed3e0d13824d17d694c79d2ece92fa"
   },
   "outputs": [],
   "source": [
    "#data_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5e51d00e-62fd-4141-bf73-50ac4f2da7d0",
    "_execution_state": "idle",
    "_uuid": "84bbd5ab8d7895bd430d5ecfe2f7ddf77baa7b74"
   },
   "outputs": [],
   "source": [
    "# randomizing the train data\n",
    "data_train = data_train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "img_rows, img_cols, img_chnls = 28, 28, 1\n",
    "input_shape = (img_rows, img_cols, img_chnls)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "y_train = to_categorical(data_train['label'],num_classes) # one-hot encoding\n",
    "X_train = data_train.drop(labels = ['label'],axis = 1)\n",
    "\n",
    "# test data\n",
    "X_test = data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can only perform the reshape on the numpy.ndarray, so you need to use either `X_train.values` or `np.array(X_train)` for the reshaping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train), type(X_train.values), type(np.array(X_train)), type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the input data into images\n",
    "X_train = X_train.values.reshape(-1, *input_shape) # -1 means infer the dimension\n",
    "X_test = X_test.values.reshape(-1, *input_shape) # -1 means infer the dimension\n",
    "\n",
    "# labels (not needed)\n",
    "\n",
    "# noramlizing the pixels values\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "for i in range(num_classes):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    index = np.random.choice(np.where(data_train.iloc[:, 0][:]==i)[0])\n",
    "    img = X_train[index].reshape(28,28)\n",
    "    plt.imshow(img, interpolation='none')\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.title(i)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "32152fc3-a570-4d64-8a7d-6c689a4acd33",
    "_uuid": "d8abbbf31483b94e1b29d07c4c8253d1311648a7"
   },
   "source": [
    "### Splitting Train Data: ~ Optional\n",
    "This is an optional step, but an important one nonetheless. Perform this step, if you want to control the train/val split (especially if you've an unbalanced dataset, i.e. uneven class split/distribution). If you're skipping this step, or if it's not applicable, you should set the `validation_split` to appropriate fraction of the `train` data in the `fit` method.\n",
    "\n",
    "**Reason:** In some unbalanced datasets a simple random split could cause inaccurate evaluation during the validation. To avoid that, use `stratify = True` option in train_test_split function (**Only for >=0.17 sklearn versions**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3a698301-9759-4279-ae48-fd980f89ea53",
    "_execution_state": "idle",
    "_uuid": "6e51c925c6e0f1b936679c9649fef345c853555f"
   },
   "outputs": [],
   "source": [
    "# split the train and the validation set for the fitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state=2018, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d5265777-aeb3-449d-b171-d88cad74c0a4",
    "_uuid": "5fa18b37a9acd9e098bac1d12264b0dd4310fdd3"
   },
   "source": [
    "### Building Model:\n",
    "**Custom model:** Load a pre-trained model or create your own here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_func_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1e0f3f88-2ad7-459e-8e02-aecc5f3511ae",
    "_execution_state": "idle",
    "_uuid": "f7991ef6871a26f9fa57acdcd460a69bab53e804"
   },
   "outputs": [],
   "source": [
    "def custom_model(input_shape=None):\n",
    "\n",
    "    if input(\"If you want to load a model, enter 'yes'.\\n\") == 'yes': \n",
    "        return my_func_utils.load_model()\n",
    "    \n",
    "    assert input_shape != None\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu')) \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "    \n",
    "    optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b5987a18-6bbe-42a2-9d31-333ebc4f7af1",
    "_execution_state": "idle",
    "_uuid": "c4a5b4e462ec5362c47eef4fcc7956fd4e203307"
   },
   "source": [
    "### Training:\n",
    "**Set Training Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "970db455-b393-4b25-806d-92c6766c12c0",
    "_execution_state": "idle",
    "_uuid": "26b0647c46efdb6b1096cf7335a7bf2a3417543a"
   },
   "outputs": [],
   "source": [
    "epochs = 2 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 32\n",
    "\n",
    "# callbacks\n",
    "anneal_lr = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=1e-5)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "241a0f4f-13f5-4b13-be1e-4e3e4a714c06",
    "_uuid": "f24df64b223e0177c94025b6767ab19b722c5386"
   },
   "source": [
    "**Without data augmentation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_model(input_shape)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ade93d2d-90c6-4401-af95-f7d65f8c0a20",
    "_execution_state": "idle",
    "_uuid": "d4e9e1ade3c04f9ca4d8cd44e799f9e09524d5a1"
   },
   "outputs": [],
   "source": [
    "history_no_aug = model.fit(X_train, y_train, \n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs, \n",
    "                    callbacks = [anneal_lr, early_stopping],\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    #verbose  = 0,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ade93d2d-90c6-4401-af95-f7d65f8c0a20",
    "_execution_state": "idle",
    "_uuid": "d4e9e1ade3c04f9ca4d8cd44e799f9e09524d5a1"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ade93d2d-90c6-4401-af95-f7d65f8c0a20",
    "_execution_state": "idle",
    "_uuid": "d4e9e1ade3c04f9ca4d8cd44e799f9e09524d5a1"
   },
   "outputs": [],
   "source": [
    "print('Validation Loss: {:8.4f}, Validation Accuracy: {:4.2f}'.format(score[0],score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b342befe-1a6f-44bf-8dab-28033a729122",
    "_execution_state": "idle",
    "_uuid": "21d6192c87d92d497c797656474bccd9cefc5647"
   },
   "source": [
    "**With data augmentation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_model(input_shape)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b342befe-1a6f-44bf-8dab-28033a729122",
    "_execution_state": "idle",
    "_uuid": "21d6192c87d92d497c797656474bccd9cefc5647"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=10,\n",
    "                             zoom_range = 0.1, \n",
    "                             width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                             height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                            )\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "22f80b8a-d4f6-4a34-b33d-ff7334f45d94",
    "_uuid": "51f16d0a5b9d9373438474e7defa7348359d7c18"
   },
   "source": [
    "**Note**:  The above data augmantations were chosen because they closely resemble the variation in data that can occur in real-time. \n",
    "\n",
    "Augmentations such as, `vertical_flip`, `horizontal_flip` have been skipped, as they don't lend themselves well, to the current dataset, i.e. using `vertical_flip`, `horizontal_flip` together could lead to misclassification of 6 and 9, 2 and 5, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b453af8d-9736-43e3-b486-7a1cd7dd8909",
    "_execution_state": "idle",
    "_uuid": "cf36b3d029f95b553be02d612e097a9769ee8252"
   },
   "outputs": [],
   "source": [
    "history_aug = model.fit_generator(datagen.flow(X_train,y_train, \n",
    "                                               batch_size=batch_size),\n",
    "                                               epochs = epochs, \n",
    "                                               validation_data = (X_val,y_val),\n",
    "                                               verbose = 2, \n",
    "                                               steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                                               callbacks=[anneal_lr, early_stopping],\n",
    "                                               #verbose  = 0,\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_val, y_val)\n",
    "print('Validation Loss: {%.4f}, Validation Accuracy: {%.2f}'.format(score[0],score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input(\"If you want to save the model, enter 'yes'.\\n\") == 'yes': \n",
    "        return my_func_utils.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e758621d-b27b-40ff-a93f-bebd2e0e5243",
    "_uuid": "0a1834f2a9f2db15dcaba4a84004b9627d714469"
   },
   "source": [
    "### Evaluating Model:\n",
    "**Train vs Validation Plot - Accuracy and Loss**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eb4b1b73-cbd4-40e8-9790-066fcef4c4c0",
    "_execution_state": "idle",
    "_uuid": "3a831860dd5bb65c8ead1ddcf4ae18ae20dd7f3e"
   },
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history_no_aug.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history_no_aug.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history_no_aug.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history_no_aug.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "de1c65bd-4a88-4351-9f4b-562e72e7e0fd",
    "_uuid": "63698d7d51381b33892ce164b0f21930abb3e937"
   },
   "source": [
    "**Confusion Matrix:** Custom Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "11361e73-8250-4bf5-a353-b0f8ea83e659",
    "_execution_state": "idle",
    "_uuid": "16e161179bf1b51ba66c39b2cead883f1db3a9c7"
   },
   "outputs": [],
   "source": [
    "# Look at confusion matrix \n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll plot the confusion matrix for our predictions on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "11361e73-8250-4bf5-a353-b0f8ea83e659",
    "_execution_state": "idle",
    "_uuid": "16e161179bf1b51ba66c39b2cead883f1db3a9c7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# plot the confusion matrix\n",
    "y_pred = model.predict(X_val)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, y_pred), classes = range(10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ef54d686-6f79-4d96-a5a0-a64657bd742e",
    "_execution_state": "idle",
    "_uuid": "afd59cae1115188b77abd3471e5e89790cef80a0"
   },
   "source": [
    "**Investigating for Errors:**\n",
    "\n",
    "I want to see the most important errors . For that purpose i need to get the difference between the probabilities of real value and the predicted ones in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7b0f31b8-c18b-4529-b0d8-eb4c31e30bbf",
    "_execution_state": "idle",
    "_uuid": "e7a3d6449b499a29db224e42e950f21ca1ec4e36"
   },
   "outputs": [],
   "source": [
    "# Display some error results \n",
    "\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[-6:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d21c4caf-e699-4647-8ef4-e60e868607ae",
    "_execution_state": "idle",
    "_uuid": "afc408bd5545a6a2b2d4e04989890546263cb642"
   },
   "source": [
    "The most important errors are also the most intrigous. \n",
    "\n",
    "For those six case, the model is not ridiculous. Some of these errors can also be made by humans, especially for one the 9 that is very close to a 4. The last 9 is also very misleading, it seems for me that is a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "05ff3b9f-c3bb-4cec-a8c2-2c128e8f15b3",
    "_execution_state": "idle",
    "_uuid": "7f17e7bf0a54a01a52fef2d554780f6bc6580dc6"
   },
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b5f1f39f-13b8-439a-8913-0f120e3d47a9",
    "_execution_state": "idle",
    "_uuid": "369dfaab09240f3f12bcff91953ffd315ab84985"
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
