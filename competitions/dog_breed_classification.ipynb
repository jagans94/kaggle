{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4c08f48-fe23-4ddb-ac46-d97f05397514",
    "_uuid": "f2156d1dd26a1243e18512002e10872c5bd7271e"
   },
   "source": [
    "# Dog Breed Identification\n",
    "\n",
    "**Overview:**\n",
    "- What I've learnt?\n",
    "- Download and Prepare Data\n",
    "- Visualize/Inspect Data\n",
    "- Building Model\n",
    "- Training Model\n",
    "- Evaluating Model\n",
    "- Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Steps:**\n",
    "\n",
    "1. Download and move the dataset to `../dataset` folder.\n",
    "2. Unpack the zipped files (optionally delete the zip files after unpacking)\n",
    "3. Visualize/Inspect the dataset.\n",
    "4. Follow chapter 5 of 'Deep Learning with Python' by Franchois Chollet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What I've learnt?\n",
    "- Concepts:\n",
    "- Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f67b9393-8ea1-4e23-b856-2ce149cfe421",
    "_execution_state": "idle",
    "_uuid": "72334cb006d02a4bcfc2a2fe622524eba824c6f8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from helper_scripts import my_func_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading, Testing  and Cleaning Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_csv('..\\datasets\\dog_breed_identification\\labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_func_utils.bin_dataset('..\\datasets\\dog_breed_identification\\copy-train-2', mapping.values, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (150,150,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(mapping.values[:,1])\n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = '../datasets/dog_breed_identification/copy-train-2/train'\n",
    "val_directory = '../datasets/dog_breed_identification/copy-train-2/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(train_directory,labels[0])\n",
    "fnames = [fname for fname in os.listdir(path)]\n",
    "fpath = os.path.join(path, fnames[0])\n",
    "img = cv2.imread(fpath,-1)\n",
    "print(fpath)\n",
    "plt.imshow(img, interpolation='none')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.title(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d5265777-aeb3-449d-b171-d88cad74c0a4",
    "_uuid": "5fa18b37a9acd9e098bac1d12264b0dd4310fdd3"
   },
   "source": [
    "### Building Model:\n",
    "**Custom model:** Load a pre-trained model or create your own here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1e0f3f88-2ad7-459e-8e02-aecc5f3511ae",
    "_execution_state": "idle",
    "_uuid": "f7991ef6871a26f9fa57acdcd460a69bab53e804"
   },
   "outputs": [],
   "source": [
    "def custom_model_1(input_shape=None):\n",
    "\n",
    "    if input(\"If you want to load a model, enter 'yes'.\\n\") == 'yes': \n",
    "        return my_func_utils.load_model()\n",
    "    \n",
    "    assert input_shape != None\n",
    "    \n",
    "    # model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPool2D((2,2,)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D((2,2,)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D((2,2,)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D((2,2,)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile params\n",
    "    optimizer = RMSprop(lr=1e-4)\n",
    "    \n",
    "    # compile\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../datasets/dog_breed_identification/copy-train-2/train'\n",
    "val_dir = '../datasets/dog_breed_identification/copy-train-2/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageDataGenerator.flow_from_directory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem #1**: Loading images with/without using generators.\n",
    "\n",
    "**Solution: **\n",
    "- Write custom library for flowing data from directory (or)\n",
    "- Write scripts to allow preprocessing using existing `Keras` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                   )\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                target_size=(150,150),\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing generators\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    for i in range(32):\n",
    "        plt.subplot(5,8,i+1)\n",
    "        img = data_batch[i].reshape(150,150,3)\n",
    "        plt.imshow(img, interpolation='none')\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "        plt.title(i)\n",
    "        plt.tight_layout()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch.shape, labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch = 100,\n",
    "                             epochs = 30,\n",
    "                             validation_data = val_generator,\n",
    "                             validation_steps = 50,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('../saved_models/dog_breed_identification_small.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eb4b1b73-cbd4-40e8-9790-066fcef4c4c0",
    "_execution_state": "idle",
    "_uuid": "3a831860dd5bb65c8ead1ddcf4ae18ae20dd7f3e"
   },
   "outputs": [],
   "source": [
    "# plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using data augmentation\n",
    "datagen = ImageDataGenerator(rotation_range=40,\n",
    "                            width_shift_range=0,\n",
    "                            height_shift_range=0.2,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest',\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying randomly augmented images\n",
    "fnames = [os.path.join(train_class_dir, fname) for fname in os.listdir(train_class_dir)]\n",
    "\n",
    "img_path = fnames[3]\n",
    "\n",
    "img = image.load_img(img_path, target_size = (150,150))\n",
    "x = image.img_to_array(img)\n",
    "x = x.reshape(1, *x.shape)\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size = 1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0: break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model_2(input_shape=None):\n",
    "\n",
    "    if input(\"If you want to load a model, enter 'yes'.\\n\") == 'yes': \n",
    "        return my_func_utils.load_model()\n",
    "    \n",
    "    assert input_shape != None\n",
    "    \n",
    "    # model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPool2D((2,2,)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D((2,2,)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D((2,2,)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D((2,2,)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile params\n",
    "    optimizer = RMSprop(lr=1e-4)\n",
    "    \n",
    "    # compile\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training network using data augmentation and dropout\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest',\n",
    "                                   )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                   )\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                target_size=(150,150),\n",
    "                                                   )\n",
    "\n",
    "# training\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch = 100,\n",
    "                             epochs = 100,\n",
    "                             validation_data = val_generator,\n",
    "                             validation_steps = 50,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('../saved_models/dog_breed_identification_small_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usinf Pre-trained Convnet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights = 'imagenet',\n",
    "                  include_top = False,\n",
    "                  input_shape = (150,150,3),\n",
    "                 )\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast feature extraction w/o data aug\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDatagenerator\n",
    "\n",
    "base_dir = ''\n",
    "train_dir = ''\n",
    "val_dir = ''\n",
    "test_dir = ''\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                            )\n",
    "\n",
    "def extract_features(directory,sample_count):\n",
    "    features = np.zeros(shape=(sample_count,4,4,512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow-from_directory(directory,\n",
    "                                           target_size = (150, 150),\n",
    "                                           batch_size batch_size,\n",
    "                                           class_mode = 'categorical',\n",
    "                                           )\n",
    "    \n",
    "    i = 0\n",
    "    for input_batch, labels_batch in generrator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch-size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch-size : (i + 1) * batch_size] = labels_batch\n",
    "        \n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count: break\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train, 2000)\n",
    "val_features, val_labels = extract_feattures(val_dir, 2000)\n",
    "test_features, test_labels = extract_feattures(test_dir, 2000)\n",
    "\n",
    "train_features = train_features.reshape(2000,-1)\n",
    "val_features = val_features.reshape(2000,-1)\n",
    "test_features = test_features.reshape(2000,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining and training densely connected classifier\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout dense\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation = 'relu', input_dims = 4 * 4 * 512))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(120, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizers = RMSprop(lr = 2e-5),\n",
    "             loss = 'categorical_cross_entropy',\n",
    "             metrics = ['acc'])\n",
    "\n",
    "history = model.fit(train-features, train_labels,\n",
    "                    epochs = 10,\n",
    "                    batch_size = 20,\n",
    "                    validation_data = (validation_features, validation_labels),\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('../saved_models/dog_breed_identification_small_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction with data aug\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "modl.add(dense(120, activation = 'softamax'))\n",
    "\n",
    "model.summary()/B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The no. of trainable weights b4 freezingt the conv_base:', len(modedl.trainable-weights))\n",
    "conv_base.trainable_wewights = False\n",
    "print('The no. of trainable weights after freezingt the conv_base:', len(modedl.trainable-weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model end to end with a feozen conv_base\n",
    "\n",
    "from keras .preprocessing.image = ImageDatagenerator\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# training network using data augmentation and dropout\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest',\n",
    "                                   )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                   )\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                target_size=(150,150),\n",
    "                                                   )\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# training\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch = 100,\n",
    "                             epochs = 100,\n",
    "                             validation_data = val_generator,\n",
    "                             validation_steps = 50,\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing all layers upto a specific one\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name = '':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else;\n",
    "    layer.trainable  =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# training\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch = 100,\n",
    "                             epochs = 100,\n",
    "                             validation_data = val_generator,\n",
    "                             validation_steps = 50,\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothing the plots\n",
    "def smooth curve(points, factor = 0.8):\n",
    "    smoothed_pints= []\n",
    "    for point i points:\n",
    "        if smoothed_points:\n",
    "            previosu = smoothed_points[-1]\n",
    "            smoothed_points.append(ptrevious * factor = point * (1 - faxctoe))\n",
    "        else:\n",
    "            smoothed_oints.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "plt.plot(epochs, smooth_curves(acc), 'bo', label = 'Smoothed Training Curve')\n",
    "plt.plot(epochs, smooth_curves(val_cc), 'b-', label = 'Smoothed Va;idation Curve')\n",
    "plt.title(\"Trainign/validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, smooth_curves(loss), 'bo', label = 'Smoothed Training Curve')\n",
    "plt.plot(epochs, smooth_curves(val_loss), 'b-', label = 'Smoothed Training Curve')\n",
    "plt.title('ead')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                target_size=(150,150),\n",
    "                                                   )\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps = 50)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Convet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intermediate Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('')\n",
    "modeel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path= ''\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import numpy\n",
    "\n",
    "img = image.load_img(img_path, target_size = (150,150))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tenssor, axis= 0)\n",
    "img_tensor = /= 255\n",
    "\n",
    "print(img_trnsor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "layer_outputs = [layer.output for layers in moodel.layers[:8]]\n",
    "activation_model = Model(input = model.input, outputs = layer_outputs)\n",
    "\n",
    "activations = activation_model.predict(img_tensor)\n",
    "\n",
    "first_layer_activation = actiation[0]\n",
    "print(first_layer_activation.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(first_layer_acivatiosn[0,:,:,4], cmap = 'virdis')\n",
    "\n",
    "plt.matshow(first_layer_acivatiosn[0,:,:,7], cmap = 'virdis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing every channel in every intermediate activation\n",
    "layer_names = []\n",
    "for layer in model.layers[:8]:\n",
    "    layer_names.append9layer.names)\n",
    "\n",
    "    images-pera_row = 16\n",
    "    \n",
    "    for layer_name, layer_activation in zip(layer-names, activations):\n",
    "        n_features = layer_activations.shape[-1]\n",
    "        \n",
    "        size = layer_activaations.shape[1]\n",
    "        \n",
    "        n_cols = n_features\n",
    "        display_grip = np.zeros((size * n_cols, images_per_row * size))\n",
    "        \n",
    "        for col in rrange(n_cols):\n",
    "            for row i range(images_per_roe):\n",
    "                channel_img = layer_activation[0,:,:, col * images_per_row + row]\n",
    "                channel_img -= channesl__imaeg.m\n",
    "                channel_img *= 64\n",
    "                channel_img += 128\n",
    "                channel_img = np.clip(channel_image, 0 ,25).as_type('unint8')\n",
    "                \n",
    "                display_grid[col * size : (col + 1) * size, \n",
    "                             row * size : (row + 1) * size, ] = cahnel_image\n",
    "                \n",
    "                scale = 1./size\n",
    "               \n",
    "            \n",
    "            plt.figure(figsize(=(scale + display_gri.shape[1],\n",
    "                                scale + display_gri.shape[0])))\n",
    "            \n",
    "            plt.title(layer-name)\n",
    "            plt.grid(False)\n",
    "            plt.imshow(display_grid, aspect='auto', cmo= 'virdis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing ConvNet Filyters\n",
    "\n",
    "from keras.applications imprt VGG16\n",
    "from keras import backend as K\n",
    "\n",
    "model = VGG16(weights = 'imagenet',\n",
    "              include_top = False,\n",
    "             )\n",
    "\n",
    "layer_name = 'block3-conv1'\n",
    "filter_index = 0\n",
    "\n",
    "layer-output = model.getlayer(layer_name).output\n",
    "loss = K.mean(layer_output[:,:,:,filter_index])\n",
    "\n",
    "grads = K.gradients(loss, model.input[0])\n",
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "iteraate = K.function([model.input], [loss, grads])\n",
    "\n",
    "import numpy as np\n",
    "loss_value, grads_value = iterate([np.zeros([1,150,150,3])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss maximization via stochastic gradient de=scent\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
